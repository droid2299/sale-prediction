{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MLtvoiYPCovb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP8N6Ya2ChPh"
      },
      "outputs": [],
      "source": [
        "def save_forecast_results(model_results, steps=12, last_date='2022-02-28'):\n",
        "    \"\"\"\n",
        "    Generate and save forecast results based on a time series model.\n",
        "\n",
        "    Parameters:\n",
        "    - model_results (object): The result object from a time series forecasting model.\n",
        "    - steps (int, optional): Number of steps (future time points) to forecast. Default is 12.\n",
        "    - last_date (str, optional): The last date in the historical data. Default is '2022-02-28'.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing forecasted values for each future date.\n",
        "    \"\"\"\n",
        "    # Generate forecast based on the provided number of steps\n",
        "    forecast = model_results.get_forecast(steps=steps)\n",
        "\n",
        "    # Convert forecasted values back to the original scale\n",
        "    forecasted_values = np.exp(forecast.predicted_mean)\n",
        "\n",
        "    # Generate future dates for the forecast\n",
        "    future_dates = pd.date_range(start=last_date, periods=steps + 1, freq='M')[1:]\n",
        "\n",
        "    # Create a dictionary mapping each future date to its corresponding forecasted value\n",
        "    forecast_dict = {date.strftime(\"%b-%Y\"): value for date, value in zip(future_dates, forecasted_values)}\n",
        "\n",
        "    return forecast_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "\n",
        "def preprocess_and_fit_model(data, product_name, split_date):\n",
        "    \"\"\"\n",
        "    Preprocess the data for a specific product, split it into training and testing sets,\n",
        "    fit a SARIMA model, and save the model weights. Evaluate the model's forecast on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    - data (DataFrame): The input time series data containing 'Products' and 'VALUE'.\n",
        "    - product_name (str): The specific product to analyze.\n",
        "    - split_date (str): The date to split the data into training and testing sets.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: A tuple containing the product name and a dictionary with forecasted values, MSE, and MAE.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filter data for the specific product and create a copy to avoid SettingWithCopyWarning\n",
        "    product_data = data[data['Products'] == product_name].copy()\n",
        "\n",
        "    # Convert REF_DATE to datetime\n",
        "    product_data['REF_DATE'] = pd.to_datetime(product_data['REF_DATE'])\n",
        "\n",
        "    # Set REF_DATE as the index and specify the frequency\n",
        "    product_data.set_index('REF_DATE', inplace=True)\n",
        "    product_data.index.freq = 'MS'  # Monthly Start frequency\n",
        "\n",
        "    # Log transformation\n",
        "    product_data['VALUE_log'] = np.log(product_data['VALUE'] + 1)  # +1 to handle 0 values\n",
        "\n",
        "    # Split the data\n",
        "    split_date = pd.to_datetime(split_date)\n",
        "    train = product_data[product_data.index < split_date]\n",
        "    test = product_data[product_data.index >= split_date]\n",
        "\n",
        "    # Fit SARIMA model\n",
        "    model_results = fit_sarima_model(train, product_name, grid_search=True)\n",
        "\n",
        "    # Save the model weights\n",
        "    model_results.save(f'/content/drive/MyDrive/Intro to ML PR/Project/Weights/{product_name}_model.pkl')\n",
        "\n",
        "    # Save forecast results\n",
        "    forecasts = save_forecast_results(model_results, steps=14, last_date='2020-12-01')\n",
        "\n",
        "    if len(test['VALUE']) == len(list(forecasts.values())):\n",
        "        # Calculate MSE and MAE\n",
        "        mse = mean_squared_error(test['VALUE'], list(forecasts.values()))\n",
        "        mae = mean_absolute_error(test['VALUE'], list(forecasts.values()))\n",
        "\n",
        "        # Save MSE and MAE to the forecasts dictionary\n",
        "        forecasts['mse'] = mse\n",
        "        forecasts['mae'] = mae\n",
        "\n",
        "        return product_name, forecasts\n",
        "    else:\n",
        "        return product_name, forecasts\n"
      ],
      "metadata": {
        "id": "4RLQhqWNCn9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import itertools\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "def fit_sarima_model(data, product_name, order=(1,1,1), seasonal_order=(1,1,1,12), grid_search=False):\n",
        "  \"\"\"\n",
        "    Fit a SARIMA (Seasonal AutoRegressive Integrated Moving Average) model to the input time series data.\n",
        "\n",
        "    Parameters:\n",
        "    - data (DataFrame): The input time series data with a 'VALUE_log' column.\n",
        "    - product_name (str): The name of the product for identification purposes.\n",
        "    - order (tuple, optional): Non-seasonal order of the SARIMA model. Default is (1, 1, 1).\n",
        "    - seasonal_order (tuple, optional): Seasonal order of the SARIMA model. Default is (1, 1, 1, 12) for monthly data.\n",
        "    - grid_search (bool, optional): Perform a grid search for optimal hyperparameters if True. Default is False.\n",
        "\n",
        "    Returns:\n",
        "    - object: The results object containing information about the fitted SARIMA model.\n",
        "    \"\"\"\n",
        "    if grid_search == False:\n",
        "      model = sm.tsa.statespace.SARIMAX(data['VALUE_log'],\n",
        "                                        order=order,\n",
        "                                        seasonal_order=seasonal_order,\n",
        "                                        enforce_stationarity=False,\n",
        "                                        enforce_invertibility=False)\n",
        "\n",
        "      # Increase the number of iterations and optionally change the optimization method\n",
        "      results = model.fit(maxiter=500, method='nm', disp=False)  # 'nm' stands for Nelder-Mead\n",
        "    else:\n",
        "      # Suppressing warnings for model convergence issues during grid search\n",
        "      warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "      # Defining the range of parameters to test\n",
        "      p = d = q = range(0, 3)  # Considering values 0, 1, 2\n",
        "      pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "      # Seasonal component - assuming an annual seasonality (s=12)\n",
        "      seasonal_pdq = [(x[0], x[1], x[2], 12) for x in pdq]\n",
        "\n",
        "      # Grid Search\n",
        "      best_aic = float(\"inf\")\n",
        "      best_pdq = None\n",
        "      best_seasonal_pdq = None\n",
        "\n",
        "      for param in tqdm(pdq, desc=f'PDQ Range for {product_name}'):\n",
        "          # for seasonal_param in tqdm(seasonal_pdq, desc='Seasonal PDQ Range'):\n",
        "          for seasonal_param in seasonal_pdq:\n",
        "              try:\n",
        "                  model = sm.tsa.statespace.SARIMAX(data['VALUE_log'],\n",
        "                                                    order=param,\n",
        "                                                    seasonal_order=seasonal_param,\n",
        "                                                    enforce_stationarity=False,\n",
        "                                                    enforce_invertibility=False)\n",
        "                  results = model.fit(method='nm', disp=False)\n",
        "                  if results.aic < best_aic:\n",
        "                      best_aic = results.aic\n",
        "                      best_pdq = param\n",
        "                      best_seasonal_pdq = seasonal_param\n",
        "              except:\n",
        "                  continue\n",
        "\n",
        "      model = sm.tsa.statespace.SARIMAX(data['VALUE_log'],\n",
        "                                                    order=best_pdq,\n",
        "                                                    seasonal_order=best_seasonal_pdq,\n",
        "                                                    enforce_stationarity=False,\n",
        "                                                    enforce_invertibility=False)\n",
        "      results = model.fit(max_iter=500, method='nm', disp=False)\n",
        "\n",
        "\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "RubzUvtBC00g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def model_and_forecast(data):\n",
        "    \"\"\"\n",
        "    Perform parallel preprocessing, SARIMA model fitting, and forecasting for each unique product in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - data (DataFrame): The input time series data.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing product names and their corresponding forecast results.\n",
        "    \"\"\"\n",
        "    # Get unique product names from the 'Products' column\n",
        "    unique_products = data['Products'].unique()\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel execution of preprocess_and_fit_model function\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Create a dictionary to map future objects to their respective products\n",
        "        future_to_product = {executor.submit(preprocess_and_fit_model, data, product, '2020-12-31'): product for product in unique_products}\n",
        "\n",
        "        # Initialize a dictionary to store all forecasts\n",
        "        all_forecasts = {}\n",
        "\n",
        "        # Iterate through completed futures using as_completed\n",
        "        for future in tqdm(concurrent.futures.as_completed(future_to_product), desc='Multi Threading'):\n",
        "            product = future_to_product[future]\n",
        "            try:\n",
        "                # Retrieve the result of the future (product and its forecasts)\n",
        "                product_forecasts = future.result()\n",
        "            except Exception as exc:\n",
        "                print(f'{product} generated an exception: {exc}')\n",
        "            else:\n",
        "                # Store the forecasts in the all_forecasts dictionary\n",
        "                all_forecasts[product] = product_forecasts\n",
        "\n",
        "    return all_forecasts"
      ],
      "metadata": {
        "id": "JtNmQTZoC29c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Intro to ML PR/Project/18100002-trimmed.csv')\n",
        "\n",
        "# Run the main function\n",
        "product_forecasts = model_and_forecast(data)"
      ],
      "metadata": {
        "id": "9MFbsTvIC3nT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}